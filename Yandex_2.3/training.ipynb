{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Based on\n",
    "Quantum graph neural network (quantum GNN) for molecular property prediction\n",
    "\n",
    "@article{tsubaki2018fast,\n",
    "  title={Fast and Accurate Molecular Property Prediction: Learning Atomic Interactions and Potentials with Neural Networks},\n",
    "  author={Tsubaki, Masashi and Mizoguchi, Teruyasu},\n",
    "  journal={The journal of physical chemistry letters},\n",
    "  volume={9},\n",
    "  number={19},\n",
    "  pages={5733--5741},\n",
    "  year={2018},\n",
    "  publisher={ACS Publications}\n",
    "}\n",
    "https://github.com/masashitsubaki/QuantumGNN_molecules\n",
    "'''\n",
    "import pickle\n",
    "import sys\n",
    "import timeit\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumGNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantumGNN, self).__init__()\n",
    "        self.embed_atom = nn.Embedding(n_atoms, dim)\n",
    "        self.gamma = nn.ParameterList([nn.Parameter(\n",
    "                     torch.FloatTensor([1.0]).to(device))\n",
    "                     for _ in range(layer_hidden)])\n",
    "        self.W_atom = nn.ModuleList([nn.Linear(dim, dim)\n",
    "                                     for _ in range(layer_hidden)])\n",
    "        self.W_output = nn.ModuleList([nn.Linear(2*dim, 2*dim)\n",
    "                                       for _ in range(layer_output)])\n",
    "        self.W_property = nn.Linear(2*dim, 1)\n",
    "\n",
    "    def pad(self, matrices, pad_value):\n",
    "        \"\"\"Pad distance matrices with pad_value for batch processing.\"\"\"\n",
    "        shapes = [m.shape[0] for m in matrices]\n",
    "        M = sum(shapes)\n",
    "        pad_matrices = pad_value + np.zeros((M, M))\n",
    "        i = 0\n",
    "        for j, m in enumerate(matrices):\n",
    "            j = shapes[j]\n",
    "            pad_matrices[i:i+j, i:i+j] = m\n",
    "            i += j\n",
    "        return torch.FloatTensor(pad_matrices).to(device)\n",
    "\n",
    "    def sum_axis(self, xs, axis, masks):\n",
    "        y = [torch.sum(x * y, 0) for x, y in zip(torch.split(masks, axis), torch.split(xs, axis))]\n",
    "        #y = [torch.sum(x, 0) for x in torch.split(xs, axis)]\n",
    "        return torch.stack(y)\n",
    "\n",
    "    def mean_axis(self, xs, axis):\n",
    "        #y = [torch.mean(x, 0) for x in torch.split(xs, axis)]\n",
    "        y = [torch.mean(x * y, 0) for x, y in zip(torch.split(masks, axis), torch.split(xs, axis))]\n",
    "        return torch.stack(y)\n",
    "\n",
    "    def update(self, xs, V, i, M):\n",
    "        \"\"\"Update each atom vector considering (i.e., sum or mean)\n",
    "        (1) all other atom vectors non-linear transformed by neural network\n",
    "        and (2) the distances (potentials V) between two atoms in a molecule.\n",
    "        \"\"\"\n",
    "        hs = torch.relu(self.W_atom[i](xs))\n",
    "        if update == 'sum':\n",
    "            return xs + torch.matmul(V, hs)\n",
    "        if update == 'mean':\n",
    "            return xs + torch.matmul(V, hs) / (M-1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        atoms, distances, masks = inputs\n",
    "\n",
    "        axis = [len(a) for a in atoms]\n",
    "\n",
    "        M = np.concatenate([np.repeat(len(a), len(a)) for a in atoms])\n",
    "        M = torch.unsqueeze(torch.FloatTensor(M).to(device), 1)\n",
    "\n",
    "        atoms = torch.cat(atoms)\n",
    "        atom_vectors = self.embed_atom(atoms)\n",
    "\n",
    "        distances = self.pad(distances, 1e6)\n",
    "        \n",
    "        masks = np.concatenate(masks)\n",
    "        masks = torch.unsqueeze(torch.FloatTensor(masks).to(device), 1)\n",
    "\n",
    "        atom_vectors_ = atom_vectors.clone()  # For concat in the last layer.\n",
    "        for i in range(layer_hidden):\n",
    "            potentials = torch.exp(-self.gamma[i]*distances**2)\n",
    "            atom_vectors = self.update(atom_vectors, potentials, i, M)\n",
    "        atom_vectors = torch.cat((atom_vectors, atom_vectors_), 1)\n",
    "\n",
    "        if output == 'sum':\n",
    "            molecular_vectors = self.sum_axis(atom_vectors, axis, masks)\n",
    "        if output == 'mean':\n",
    "            molecular_vectors = self.mean_axis(atom_vectors, axis, masks)\n",
    "\n",
    "        for j in range(layer_output):\n",
    "            molecular_vectors = torch.relu(self.W_output[j](molecular_vectors))\n",
    "\n",
    "        molecular_properties = self.W_property(molecular_vectors)\n",
    "\n",
    "        return molecular_properties\n",
    "\n",
    "    def __call__(self, data_batch, train=True):\n",
    "\n",
    "        Smiles, inputs = data_batch[0], data_batch[1:-1]\n",
    "        correct_properties = torch.cat(data_batch[-1])\n",
    "        #masks = data_batch[-2]\n",
    "        predicted_properties = self.forward(inputs)\n",
    "\n",
    "        if train:\n",
    "            loss = F.mse_loss(predicted_properties, correct_properties)\n",
    "            return loss\n",
    "        else:\n",
    "            \"\"\"Transform the normalized properties (i.e., mean 0 and std 1)\n",
    "            to the unit-based properties (e.g., eV and kcal/mol).\n",
    "            \"\"\"\n",
    "            ts = correct_properties.to('cpu').data.numpy()\n",
    "            ys = predicted_properties.to('cpu').data.numpy()\n",
    "            ts = std * np.concatenate(ts) + mean\n",
    "            ys = std * np.concatenate(ys) + mean\n",
    "            return Smiles, ts, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.optimizer = optim.Adam(self.model.parameters(),\n",
    "                                    lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    def train(self, dataset):\n",
    "        np.random.shuffle(dataset)\n",
    "        N = len(dataset)\n",
    "        loss_total = 0\n",
    "        for i in range(0, N, batch):\n",
    "            data_batch = list(zip(*dataset[i:i+batch]))\n",
    "            loss = self.model(data_batch)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            loss_total += loss.to('cpu').data.numpy()\n",
    "        return loss_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def test(self, dataset):\n",
    "        N = len(dataset)\n",
    "        AE_sum, SMILES, Ts, Ys = 0, '', [], []\n",
    "        for i in range(0, N, batch):\n",
    "            data_batch = list(zip(*dataset[i:i+batch]))\n",
    "            (Smiles, correct_properties,\n",
    "             predicted_properties) = self.model(data_batch, train=False)\n",
    "            AE_sum += sum(abs(correct_properties-predicted_properties))\n",
    "            SMILES += ' '.join(Smiles) + ' '\n",
    "            Ts.append(correct_properties)\n",
    "            Ys.append(predicted_properties)\n",
    "        MAE = AE_sum / N\n",
    "        SMILES = SMILES.strip().split()\n",
    "        T = map(str, np.concatenate(Ts))\n",
    "        Y = map(str, np.concatenate(Ys))\n",
    "        predictions = '\\n'.join(['\\t'.join(x) for x in zip(SMILES, T, Y)])\n",
    "        return MAE, predictions\n",
    "\n",
    "    def save_MAEs(self, MAEs, filename):\n",
    "        with open(filename, 'a') as f:\n",
    "            f.write(MAEs + '\\n')\n",
    "\n",
    "    def save_predictions(self, predictions, filename):\n",
    "        with open(filename, 'w') as f:\n",
    "            f.write('Smiles\\tCorrect\\tPredict\\n')\n",
    "            f.write(predictions + '\\n')\n",
    "\n",
    "    def save_model(self, model, filename):\n",
    "        torch.save(model.state_dict(), filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tensor(file_name, dtype):\n",
    "    return [dtype(d).to(device) for d in np.load(file_name + '.npy')]\n",
    "\n",
    "\n",
    "def load_numpy(file_name):\n",
    "    return np.load(file_name + '.npy')\n",
    "\n",
    "\n",
    "def shuffle_dataset(dataset, seed):\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(dataset)\n",
    "    return dataset\n",
    "\n",
    "def split_dataset(dataset, ratio):\n",
    "    n = int(ratio * len(dataset))\n",
    "    dataset_1, dataset_2 = dataset[:n], dataset[n:]\n",
    "    return dataset_1, dataset_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code uses CPU!!!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CPU or GPU.\"\"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('The code uses GPU...')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('The code uses CPU!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_input = 'dataset/input/'\n",
    "molecules = load_tensor(dir_input + 'molecules', torch.LongTensor)\n",
    "properties = load_tensor(dir_input + 'coupling_constants', torch.FloatTensor)\n",
    "Distances = load_numpy(dir_input + 'distances')\n",
    "Bounds = load_numpy(dir_input + 'bounds')\n",
    "Types = load_numpy(dir_input + 'types')\n",
    "Names = load_numpy(dir_input + 'names')\n",
    "with open(dir_input + 'atom_dict.pickle', 'rb') as f:\n",
    "    atom_dict = pickle.load(f)\n",
    "with open(dir_input + 'mean_std.pickle', 'rb') as f:\n",
    "    mean_std = pickle.load(f)\n",
    "mean = mean_std['mean']\n",
    "std = mean_std['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Set a model.\"\"\"\n",
    "\n",
    "update = 'sum' # how to combine processed atom vectors in the molecule vector\n",
    "output = 'sum'\n",
    "dim = 25 # 50\n",
    "layer_hidden = 6\n",
    "layer_output = 3 # 6\n",
    "batch = 16\n",
    "decay_interval = 10\n",
    "weight_decay = 1e-6\n",
    "iteration = 20 # 1000\n",
    "lr = 1e-3\n",
    "lr_decay = 0.95\n",
    "setting = '{0}_{1}_{2}_{3}_{4}_{5}_{6}_{7}'.format(update, \n",
    "                                                   output, dim, layer_hidden, \n",
    "                                                   layer_output, batch, lr, weight_decay)\n",
    "\n",
    "n_atoms = len(atom_dict)\n",
    "torch.manual_seed(1234)\n",
    "model = QuantumGNN().to(device)\n",
    "trainer = Trainer(model)\n",
    "tester = Tester(model)\n",
    "\n",
    "bound = 1     # weight for one of the goal atom \n",
    "non_bound = 0 # weight for other atoms\n",
    "\n",
    "os.makedirs('output/result/', exist_ok=True)\n",
    "os.makedirs('output/model/', exist_ok=True)\n",
    "file_MAEs = 'output/result/MAEs--' + setting + '.txt'\n",
    "file_predictions = 'output/result/predictions--' + setting + '.txt'\n",
    "file_model = 'output/model/' + setting\n",
    "MAEs = ('Epoch\\tTime(sec)\\tLoss_train(MSE,normalized)\\t'\n",
    "            'Error_dev(MAE)\\tError_test(MAE)')\n",
    "with open(file_MAEs, 'w') as f:\n",
    "    f.write(MAEs + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [[bound if i in Bounds[j] else non_bound for i, x in enumerate(y)] for j, y in enumerate(molecules)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a dataset and split it into train/dev/test.\"\"\"\n",
    "dataset = list(zip(Names, molecules, Distances, masks, properties))\n",
    "dataset = shuffle_dataset(dataset, 1234)\n",
    "dataset_train, dataset_ = split_dataset(dataset, 0.8)\n",
    "dataset_dev, dataset_test = split_dataset(dataset_, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch\tTime(sec)\tLoss_train(MSE,normalized)\tError_dev(MAE)\tError_test(MAE)\n",
      "1\t5.246725103002973\t237.84840585291386\t22.698145723342897\t22.81229629453129\n",
      "2\t10.315820782998344\t193.12968554347754\t19.572398893038432\t19.046979824834178\n",
      "3\t13.556294739013538\t162.60643983026966\t18.839936459859214\t19.305128665613058\n",
      "4\t16.797596018994227\t138.58110648253933\t17.43245294570923\t17.883316898504628\n",
      "5\t19.982128233008552\t132.04772551171482\t14.836643856366475\t15.11036033122591\n",
      "6\t23.44905787400785\t124.78443938493729\t15.10614965279897\t15.11318269307522\n",
      "7\t28.78887362900423\t116.9940717786667\t14.011572880744934\t14.86344728136618\n",
      "8\t34.635627020004904\t108.41953287227079\t14.304635500907898\t14.639988505701455\n",
      "9\t40.57707933100755\t105.12413522135466\t13.777081265449524\t13.985538515989079\n",
      "10\t44.73209008999402\t103.10155069176108\t12.867030955950419\t13.714972218340526\n",
      "11\t50.42023141498794\t102.2906245291233\t13.661846135457356\t14.252684226646995\n",
      "12\t55.50230063899653\t99.32389688771218\t13.153511439959209\t13.969391099228439\n",
      "13\t60.05715421400964\t92.72294594533741\t13.094050620396931\t14.21267106727435\n",
      "14\t65.74339056201279\t96.9923834502697\t13.023541288375855\t13.447820244533647\n",
      "15\t71.5404211099958\t92.00318651646376\t12.045516363779704\t12.65923284095853\n",
      "16\t77.3427066669974\t89.52782124653459\t12.651324971516926\t13.18512999237873\n",
      "17\t83.12908981600776\t89.00068441126496\t13.838646621704102\t14.799230215355085\n",
      "18\t88.91881487000501\t90.53939936310053\t16.069790031115215\t16.64062609490063\n",
      "19\t94.74265082299826\t93.9530487516895\t12.501521736780802\t13.590419405907046\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Start training.\"\"\"\n",
    "print('Training...')\n",
    "print(MAEs)\n",
    "start = timeit.default_timer()\n",
    "\n",
    "for epoch in range(1, iteration):\n",
    "    if epoch % decay_interval == 0:\n",
    "        trainer.optimizer.param_groups[0]['lr'] *= lr_decay\n",
    "    loss_train = trainer.train(dataset_train)\n",
    "    MAE_dev = tester.test(dataset_dev)[0]\n",
    "    MAE_test, predictions_test = tester.test(dataset_test)\n",
    "    \n",
    "    end = timeit.default_timer()\n",
    "    time = end - start\n",
    "    \n",
    "    MAEs = '\\t'.join(map(str, [epoch, time, loss_train,\n",
    "                                   MAE_dev, MAE_test]))\n",
    "    tester.save_MAEs(MAEs, file_MAEs)\n",
    "    tester.save_predictions(predictions_test, file_predictions)\n",
    "    tester.save_model(model, file_model)\n",
    "\n",
    "    print(MAEs)\n",
    "    TODO: Можно еще попробовать добавить вектор в update где-нибудь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
